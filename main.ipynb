{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337baabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opencv-python numpy mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2a28fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a753da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import threading, winsound\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "os.environ[\"OPENCV_VIDEOIO_MSMF_ENABLE_HW_TRANSFORMS\"] = \"0\"\n",
    "import cv2\n",
    "\n",
    "from libs.hand_task import HAND_TASK\n",
    "from libs.cell_phone_task import CELL_PHONE_TASK\n",
    "from libs.head_task import HEAD_DIRECTION_TASK\n",
    "from libs.iris_task import IRIS_TASK\n",
    "\n",
    "iris_task = IRIS_TASK()\n",
    "cell_phone_task = CELL_PHONE_TASK()\n",
    "head_dir_task  = HEAD_DIRECTION_TASK()\n",
    "hand_task = HAND_TASK()\n",
    "tasks = [iris_task.process, cell_phone_task.process, head_dir_task.process, hand_task.process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "651be3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InstanceSound:\n",
    "    def __init__(self, wav_path):\n",
    "        self.wav_path = wav_path\n",
    "        self.sound_thread = self.thread_generator()\n",
    "        self.queue_to_move_back = False\n",
    "    \n",
    "    def __hash__(self): \n",
    "        # TODO: crashs maybe happen, but just-work in this case\n",
    "        return ord(self.wav_path[0])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.wav_path\n",
    "    \n",
    "    def thread_generator(self):\n",
    "        play_blocking = lambda: winsound.PlaySound(self.wav_path, winsound.SND_FILENAME)  # blocks until finished\n",
    "        return threading.Thread(target=play_blocking)\n",
    "\n",
    "    def set_on(self):\n",
    "        if not(self.is_alive()):\n",
    "            self.sound_thread = self.thread_generator()\n",
    "            self.sound_thread.start()\n",
    "            self.queue_to_move_back = True\n",
    "    \n",
    "    def is_alive(self):\n",
    "        return (\n",
    "            self.sound_thread.is_alive()\n",
    "        )\n",
    "\n",
    "class WinSoundController:\n",
    "    def __init__(self, wav_path_list: str):\n",
    "        self.all_sound_instance = [InstanceSound(path) for path in wav_path_list]\n",
    "        self.playlist = []\n",
    "\n",
    "    def current_flag(self, result_flag):\n",
    "        current_wanted_play_sound = [self.all_sound_instance[i] for i in range(len(result_flag)) if result_flag[i]]\n",
    "        need_to_add = set(current_wanted_play_sound) - set(self.playlist)\n",
    "\n",
    "        need_to_remove = set(self.playlist) - set(current_wanted_play_sound)\n",
    "        if len(self.playlist) > 0:\n",
    "            top_queue = self.playlist[0]\n",
    "            if top_queue.is_alive() or top_queue.queue_to_move_back:\n",
    "                need_to_remove -= set([top_queue])\n",
    "        \n",
    "        self.playlist = list(set(self.playlist) - set(need_to_remove)) + list(need_to_add)\n",
    "\n",
    "        if len(self.playlist) == 0:\n",
    "            return\n",
    "        top_queue = self.playlist[0]\n",
    "        if not(top_queue.queue_to_move_back):\n",
    "            top_queue.set_on()\n",
    "        if not(top_queue.is_alive()):\n",
    "            top_queue.queue_to_move_back = False\n",
    "            self.playlist.append(self.playlist.pop(0))\n",
    "    \n",
    "def add_label(res):\n",
    "    label = res[1]\n",
    "    color = (0,0,255) if res[0] else (255,0,0)  # keep your colors\n",
    "    cv2.putText(res[2], label, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    return res[2]\n",
    "\n",
    "def flag_modify_from_cell_phone_position(\n",
    "        results,\n",
    "        threshold = 200\n",
    "    ):\n",
    "    \n",
    "    mod_flag = False\n",
    "    all_hand_center_points = hand_task.all_hand_center_points\n",
    "    objs_coordinate = cell_phone_task.objs_coordinate\n",
    "    \n",
    "    if (len(all_hand_center_points) == 0) or (len(objs_coordinate) == 0):\n",
    "        results[1] = (\n",
    "            False,\n",
    "            results[1][1],\n",
    "            results[1][2]\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    for hand in all_hand_center_points:\n",
    "        hand_pos = np.array(hand)\n",
    "        for objs in objs_coordinate:\n",
    "            objs_pos = np.array(objs)\n",
    "            dist = np.linalg.norm(objs_pos-hand_pos)\n",
    "            if dist < threshold:\n",
    "                mod_flag = True\n",
    "                break\n",
    "    results[1] = (\n",
    "            mod_flag,\n",
    "            results[1][1],\n",
    "            results[1][2]\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c52d5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound.playlist[0].set_on()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77f4b0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\oit\\py25en\\source\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "list_fps = []\n",
    "\n",
    "# Use a WAV file for reliable start/stop control\n",
    "sound = WinSoundController(\n",
    "    wav_path_list = [\n",
    "        './sounds/eyes.wav',\n",
    "        './sounds/phone.wav',\n",
    "        './sounds/head.wav',\n",
    "        './sounds/steering.wav'\n",
    "    ]\n",
    ")\n",
    "verbose = True\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(tasks)) as pool:\n",
    "    while cap.isOpened():\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        futures = [pool.submit(func, frame.copy()) for func in tasks]\n",
    "        results = [f.result() for f in futures]\n",
    "        \n",
    "        results = flag_modify_from_cell_phone_position(results)\n",
    "        flag = [res[0] for res in results]\n",
    "        sound.current_flag(flag)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "        time_usage =  time.time() - start_time\n",
    "        list_fps.append(time_usage)\n",
    "        if len(list_fps) > 60:\n",
    "            del list_fps[0]\n",
    "\n",
    "        if verbose:\n",
    "            concat_images = [add_label(res) for res in results]\n",
    "            result_image = np.concatenate(\n",
    "                (\n",
    "                    np.concatenate((concat_images[0], concat_images[1]), axis=1),\n",
    "                    np.concatenate((concat_images[2], concat_images[3]), axis=1)\n",
    "                ), axis=0\n",
    "            )\n",
    "            fps_report = f\"fps:{int(len(list_fps) / sum(list_fps)):2d}\"\n",
    "\n",
    "            cv2.putText(result_image, fps_report, (30,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "            cv2.imshow('result', result_image)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2895e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = [True] * 4\n",
    "sound.current_flag(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51397939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # open both cameras\n",
    "# cap0 = cv2.VideoCapture(0)\n",
    "# cap0.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "# cap1 = cv2.VideoCapture(1)\n",
    "# cap1.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "# hand_task2 = HAND_TASK(boundary=\n",
    "#     [0.6, 0.2, 0.98, 0.9]\n",
    "# )\n",
    "\n",
    "\n",
    "# # Use a WAV file for reliable start/stop control\n",
    "# sound = WinSoundController('alert.wav')\n",
    "# verbose = True\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=len(tasks)) as pool:\n",
    "#     if not cap0.isOpened() or not cap1.isOpened():\n",
    "#         print(\"One or both cameras could not be opened\")\n",
    "#         exit()\n",
    "\n",
    "#     while True:\n",
    "#         ret0, frame0 = cap0.read()\n",
    "#         ret1, frame1 = cap1.read()\n",
    "#         if not (ret0 and ret1):\n",
    "#             break\n",
    "\n",
    "#         # resize to same height for concatenation\n",
    "#         h = min(frame0.shape[0], frame1.shape[0])\n",
    "#         frame0 = cv2.resize(frame0, (int(frame0.shape[1] * h / frame0.shape[0]), h))\n",
    "#         frame1 = cv2.resize(frame1, (int(frame1.shape[1] * h / frame1.shape[0]), h))\n",
    "        \n",
    "#         futures = [pool.submit(func, frame0.copy()) for func in tasks] + [pool.submit(hand_task2.process, frame1.copy())]\n",
    "#         results = [f.result() for f in futures]\n",
    "\n",
    "#         if verbose:\n",
    "#             concat_images = [add_label(res) for res in results]\n",
    "#             result_image = np.concatenate(\n",
    "#                 (\n",
    "#                     np.concatenate((concat_images[0], concat_images[1]), axis=1),\n",
    "#                     np.concatenate((concat_images[2], concat_images[3]), axis=1)\n",
    "#                 ), axis=0\n",
    "#             )\n",
    "#             cv2.imshow('result', result_image)\n",
    "#             cv2.imshow('result2', concat_images[-1])\n",
    "\n",
    "#             # --- SOUND LOGIC: play once while any alert is True; stop when all False ---\n",
    "#             bad_flag = any(res[0] for res in results)\n",
    "#             sound.set_on(bad_flag)\n",
    "\n",
    "#         key = cv2.waitKey(1) & 0xFF\n",
    "#         if key == ord('q'):\n",
    "#             break\n",
    "\n",
    "# cap0.release()\n",
    "# cap1.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b90e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
